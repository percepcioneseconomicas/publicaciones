{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del Sentimiento de las noticias económicas en Chile 2020\n",
    "\n",
    "En esta sección se desarrolla el **modelo clasificador de sentimiento económico**. \n",
    "\n",
    "El modelo se entrenó con una base de datos de textos económicos, constituida por noticias económicas publicadas en diversos medios de prensa online en Chile, durante abril de 2020 y abril de 2021. Las noticias fueron etiquetadas manualmente como pesimistas, neutrales y optimistas.  Adicionalmente, la base de datos contiene fragmentos de cartas a los accionistas de años anteriores, en que claramente se observa una polaridad  específica: pesimista, neutral u optimista. \n",
    "\n",
    "Los textos debían cumplir la condición de expresar claramente ideas con cierta polaridad, sin ambigüedades que pudieran confundir al algoritmo. Si, por ejemplo, un texto contenía una mezcla de ideas pesimistas y optimistas, se optaba por omitirlo, o bien se separaban los textos fragmentos en con etiquetas individuales. Otra condición importante fue que los textos contuvieran información económica, de forma que las palabras y combinaciones de palabras encontradas coincidieran con las que pudiéramos encontrar en las cartas a los accionistas. En otras palabras, los textos debían contener la jerga mayormente utilizada en los ámbitos de la economía, negocios, finanzas, marketing, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import unidecode\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "source": [
    "En primer lugar se cargan los datos. Luego:\n",
    "- Se reemplaza la etiqueta de sentimiento: 2 (neutral), por 0 (no positivo). El clasificador se entrenará sólo para identificar el sentimiento positivo.\n",
    "- Se eliminaron los *missing values* (NA).\n",
    "- Se seleccionó sólo un conjunto de las variables de la base de datos: (1) response: dummy igual 1 para los textos con sentimiento positivo, y 0 en otro caso; y (2) texto: noticia o fragmento de carta a los accionistas con una polaridad específica.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   response                                              texto\n",
       "0       1.0  En cuanto a las colocaciones, estas alcanzaron...\n",
       "1       0.0  En el año 2009 el mundo enfrentó una crisis fi...\n",
       "2       1.0  Es para mí motivo de gran satisfacción compart...\n",
       "3       1.0  Si tuviera que resumir la gestión 2012 de Cruz...\n",
       "4       1.0  El crecimiento anteriormente mencionado redund..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>response</th>\n      <th>texto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>En cuanto a las colocaciones, estas alcanzaron...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>En el año 2009 el mundo enfrentó una crisis fi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>Es para mí motivo de gran satisfacción compart...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>Si tuviera que resumir la gestión 2012 de Cruz...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>El crecimiento anteriormente mencionado redund...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/percepcioneseconomicas/publicaciones/main/sentiment_data/sentiment_data.csv')\n",
    "data['response'][data['response'] == 2.0] = 0\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data = data[['response', 'texto']]\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "La base de datos contiene **1461 observaciones** (textos económicos clasificados según polaridad)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dimensiones de los datos: \n (1461, 2) \n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1461 entries, 0 to 1460\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   response  1461 non-null   float64\n 1   texto     1461 non-null   object \ndtypes: float64(1), object(1)\nmemory usage: 23.0+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "print('Dimensiones de los datos: \\n', data.shape, '\\n')\n",
    "print(data.info())"
   ]
  },
  {
   "source": [
    "En la siguiente celda se observa que el 77% de los textos tienen un sentimiento negativo (0), mientras que sólo el 23% tiene un sentimiento positivo. Esto se debe a que los textos son principalmente noticias económicas, publicadas durante la pandemia de covid19 (año 2020), cuando la actividad económica estaba siendo seriamente afectada por la contingencia."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0    0.77\n",
       "1.0    0.23\n",
       "Name: response, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Rows en cada categoría de la variable y\n",
    "data['response'].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "source": [
    "El siguiente análisis muestra el número de palabras de la noticia más larga (2403 palabras) y la más corta (37 palabras). Se aprecia una gran diferencia en la extensión de los textos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Número de palabras de la noticia más larga: \n 2403 \n\nNúmero de palabras de la noticia más corta: \n 37 \n\n"
     ]
    }
   ],
   "source": [
    "# Número de palabras\n",
    "x = []\n",
    "[x.append(len(e.split())) for e in data['texto']]\n",
    "print('Número de palabras de la noticia más larga: \\n',  max(x), '\\n')\n",
    "print('Número de palabras de la noticia más corta: \\n',  min(x), '\\n')"
   ]
  },
  {
   "source": [
    "En la siguiente celda se muestra un texto de la base de datos seleccionado aleatoriamente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Noticia 637: \n McDonald’s informó este martes una pronunciada caída en sus beneficios durante el segundo trimestre, debido a la baja de ventas producto de los cierres por la pandemia.\n\nLa cadena de comida rápida sufrió un descenso del 68% en sus ganancias a 483,8 millones de dólares, tras una baja del 30% en sus ingresos, hasta los 3.800 millones.\n\nLas ventas se hundieron en los principales mercados en los que McDonald’s está presente.\n\nSin embargo, la cadena sostuvo que en Estados Unidos no fue tan grave gracias a que su servicio de comida para llevar continuó, pese al cierre de locales al público.\n"
     ]
    }
   ],
   "source": [
    "# Noticia aleatoria\n",
    "k = np.random.randint(0, len(data['texto']))\n",
    "print('Noticia %d:' % k, '\\n', data['texto'][k])"
   ]
  },
  {
   "source": [
    "# Preprocesamiento de los datos\n",
    "\n",
    "En esta sección se preprocesan los datos para su posterior utilización."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "En la siguiente celda se carga una lista de **Stopwords**. Las StopWords son palabras sin un significado o sentido claro—como los artículos, pronombres y preposiciones—que se usan con frecuencia en todo tipo de textos, independientemente de la polaridad, por lo que no contribuyen a la clasificación de las cartas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de stopwords\n",
    "sw = pd.read_csv('spanish.txt', header=None, names=['stopwords'])\n",
    "stopwords = sw['stopwords'].tolist()"
   ]
  },
  {
   "source": [
    "Se define una función para preprocesar los textos. Esta función:\n",
    "- Pone todas las palabras en minúsculas.\n",
    "- Quita números y caracteres especiales.\n",
    "- Separa los textos en palabras individuales.\n",
    "- Mantiene sólo las palabras que no sean Stopwords (remueve las Stopwords)\n",
    "- Une las palabras nuevamente para formar un texto."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preprocesar los datos.\n",
    "def preprocess(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub('[0-9]+', '', s) \n",
    "    s = re.sub('[!\"#$%&()*+,-./:;<=>¿?@[\\\\]^_`{|}~\\t—’‘“”]', '', s)\n",
    "    tokens = nltk.tokenize.word_tokenize(s) \n",
    "    tokens = [t for t in tokens if t not in stopwords] \n",
    "    tokens = [unidecode.unidecode(t) for t in tokens]\n",
    "    jtokens = ' '.join(tokens)\n",
    "    return jtokens"
   ]
  },
  {
   "source": [
    "En la siguiente celda se aplica la función anterior a los textos de la base de datos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "pdata = [preprocess(t) for t in data['texto']]"
   ]
  },
  {
   "source": [
    "Luego, se muestra la misma noticia de antes, después del pre procesamiento."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Noticia 637 : \n mcdonalds informo martes pronunciada caida beneficios segundo trimestre debido baja ventas producto cierres pandemia cadena comida rapida sufrio descenso ganancias millones dolares tras baja ingresos millones ventas hundieron principales mercados mcdonalds presente embargo cadena sostuvo unidos tan grave gracias servicio comida llevar continuo pese cierre locales publico\n"
     ]
    }
   ],
   "source": [
    "print('Noticia %d :' % k, '\\n', pdata[k])"
   ]
  },
  {
   "source": [
    "## Vectorización \n",
    "\n",
    "A continuación, se vectorizan los datos. Vectorizar significa dar una estructura de dataframe (matricial) a los datos, donde las cartas son las filas, y el *vocabulario* son las columnas. \n",
    "- El *vocabulario* es una lista de todas las palabras presentes en el total de textos. Este vocabulario se compone de las 3000 palabras más frecuentes.\n",
    "\n",
    "Los valores de la matriz pueden ser:\n",
    "- Recuento de palabras por texto, es decir, el número de veces que aparece cada palabra en el texto correspondiente.\n",
    "- Frecuencia porcentual de palabras por texto, donde la cifra anterior se divide por el total de palabras en el texto correspondiente, de forma de normalizar por la extensión de las cartas.\n",
    "- **Tf-idf** (term frequency – Inverse document frequency), métrica que multiplica la frecuencia con que cada palabra aparece por el inverso de la frecuencia con que aparece en el total de textos, lo que hace que las palabras más comunes tengan un menor peso en la matriz.\n",
    "\n",
    "Además de las palabras individuales se consideraron **n-grams**, que son combinaciones de palabras consecutivas. \n",
    "\n",
    "Esto es importante, ya que una palabra como *desempleo* podría tener una connotación negativa, pero su sentido cambia a positivo si se combina con otra palabra. Por ejemplo, si encontramos la combinación *desempleo disminuye*. \n",
    "\n",
    "De esta manera, se procesaron los datos de **seis** formas distintas:\n",
    "\n",
    "1. Recuento de palabras individuales.\n",
    "2. Recuento de ngrams 1 y 2.\n",
    "3. Porcentaje de palabras individuales.\n",
    "4. Porcentaje de ngrams 1 y 2.\n",
    "5. Tf-idf de palabras individuales.\n",
    "6. Tf-idf de ngrams 1 y 2.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   aa  abastecimiento  abiertas  abogado  abril  abriljunio  abrio  abrir  \\\n",
       "0   0               0         0        0      0           0      0      0   \n",
       "\n",
       "   aca  academico  ...  web  wti  xtb  yapocl  york  yuanes  zaldivar  zona  \\\n",
       "0    0          0  ...    0    0    0       0     0       0         0     0   \n",
       "\n",
       "   zonas  zoom  \n",
       "0      0     0  \n",
       "\n",
       "[1 rows x 3000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aa</th>\n      <th>abastecimiento</th>\n      <th>abiertas</th>\n      <th>abogado</th>\n      <th>abril</th>\n      <th>abriljunio</th>\n      <th>abrio</th>\n      <th>abrir</th>\n      <th>aca</th>\n      <th>academico</th>\n      <th>...</th>\n      <th>web</th>\n      <th>wti</th>\n      <th>xtb</th>\n      <th>yapocl</th>\n      <th>york</th>\n      <th>yuanes</th>\n      <th>zaldivar</th>\n      <th>zona</th>\n      <th>zonas</th>\n      <th>zoom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 3000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Conteo de palabras por texto\n",
    "vect = CountVectorizer(max_features=3000)\n",
    "vdat = vect.fit_transform(pdata)\n",
    "data1 = pd.DataFrame(vdat.toarray(), columns=vect.get_feature_names())\n",
    "data1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   abastecimiento  abogado  abril  abril junio  abril mayo  abriljunio  abrir  \\\n",
       "0               0        0      0            0           0           0      0   \n",
       "\n",
       "   aca  academico  acceder  ...  walmart  washington  web  wti  yapocl  york  \\\n",
       "0    0          0        0  ...        0           0    0    0       0     0   \n",
       "\n",
       "   zaldivar  zona  zona euro  zonas  \n",
       "0         0     0          0      0  \n",
       "\n",
       "[1 rows x 3000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abastecimiento</th>\n      <th>abogado</th>\n      <th>abril</th>\n      <th>abril junio</th>\n      <th>abril mayo</th>\n      <th>abriljunio</th>\n      <th>abrir</th>\n      <th>aca</th>\n      <th>academico</th>\n      <th>acceder</th>\n      <th>...</th>\n      <th>walmart</th>\n      <th>washington</th>\n      <th>web</th>\n      <th>wti</th>\n      <th>yapocl</th>\n      <th>york</th>\n      <th>zaldivar</th>\n      <th>zona</th>\n      <th>zona euro</th>\n      <th>zonas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 3000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Conteo de palabras y ngrams por texto\n",
    "vect = CountVectorizer(max_features=3000, ngram_range=(1,2))\n",
    "vdat = vect.fit_transform(pdata)\n",
    "data2 = pd.DataFrame(vdat.toarray(), columns=vect.get_feature_names())\n",
    "data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    aa  abastecimiento  abiertas  abogado  abril  abriljunio  abrio  abrir  \\\n",
       "0  0.0             0.0       0.0      0.0    0.0         0.0    0.0    0.0   \n",
       "\n",
       "   aca  academico  ...  web  wti  xtb  yapocl  york  yuanes  zaldivar  zona  \\\n",
       "0  0.0        0.0  ...  0.0  0.0  0.0     0.0   0.0     0.0       0.0   0.0   \n",
       "\n",
       "   zonas  zoom  \n",
       "0    0.0   0.0  \n",
       "\n",
       "[1 rows x 3000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aa</th>\n      <th>abastecimiento</th>\n      <th>abiertas</th>\n      <th>abogado</th>\n      <th>abril</th>\n      <th>abriljunio</th>\n      <th>abrio</th>\n      <th>abrir</th>\n      <th>aca</th>\n      <th>academico</th>\n      <th>...</th>\n      <th>web</th>\n      <th>wti</th>\n      <th>xtb</th>\n      <th>yapocl</th>\n      <th>york</th>\n      <th>yuanes</th>\n      <th>zaldivar</th>\n      <th>zona</th>\n      <th>zonas</th>\n      <th>zoom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 3000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Frecuencia de palabras por texto\n",
    "data1sum = data1.sum(axis=1)\n",
    "data3 = data1.divide(data1sum, axis=0)\n",
    "data3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   abastecimiento  abogado  abril  abril junio  abril mayo  abriljunio  abrir  \\\n",
       "0             0.0      0.0    0.0          0.0         0.0         0.0    0.0   \n",
       "\n",
       "   aca  academico  acceder  ...  walmart  washington  web  wti  yapocl  york  \\\n",
       "0  0.0        0.0      0.0  ...      0.0         0.0  0.0  0.0     0.0   0.0   \n",
       "\n",
       "   zaldivar  zona  zona euro  zonas  \n",
       "0       0.0   0.0        0.0    0.0  \n",
       "\n",
       "[1 rows x 3000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abastecimiento</th>\n      <th>abogado</th>\n      <th>abril</th>\n      <th>abril junio</th>\n      <th>abril mayo</th>\n      <th>abriljunio</th>\n      <th>abrir</th>\n      <th>aca</th>\n      <th>academico</th>\n      <th>acceder</th>\n      <th>...</th>\n      <th>walmart</th>\n      <th>washington</th>\n      <th>web</th>\n      <th>wti</th>\n      <th>yapocl</th>\n      <th>york</th>\n      <th>zaldivar</th>\n      <th>zona</th>\n      <th>zona euro</th>\n      <th>zonas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 3000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Frecuencia de palabras y ngrams por texto\n",
    "data2sum = data2.sum(axis=1)\n",
    "data4 = data2.divide(data2sum, axis=0)\n",
    "data4.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    aa  abastecimiento  abiertas  abogado  abril  abriljunio  abrio  abrir  \\\n",
       "0  0.0             0.0       0.0      0.0    0.0         0.0    0.0    0.0   \n",
       "\n",
       "   aca  academico  ...  web  wti  xtb  yapocl  york  yuanes  zaldivar  zona  \\\n",
       "0  0.0        0.0  ...  0.0  0.0  0.0     0.0   0.0     0.0       0.0   0.0   \n",
       "\n",
       "   zonas  zoom  \n",
       "0    0.0   0.0  \n",
       "\n",
       "[1 rows x 3000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aa</th>\n      <th>abastecimiento</th>\n      <th>abiertas</th>\n      <th>abogado</th>\n      <th>abril</th>\n      <th>abriljunio</th>\n      <th>abrio</th>\n      <th>abrir</th>\n      <th>aca</th>\n      <th>academico</th>\n      <th>...</th>\n      <th>web</th>\n      <th>wti</th>\n      <th>xtb</th>\n      <th>yapocl</th>\n      <th>york</th>\n      <th>yuanes</th>\n      <th>zaldivar</th>\n      <th>zona</th>\n      <th>zonas</th>\n      <th>zoom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 3000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Tfidf de palabras por texto\n",
    "vect = TfidfVectorizer(max_features=3000)\n",
    "vdat = vect.fit_transform(pdata)\n",
    "data5 = pd.DataFrame(vdat.toarray(), columns=vect.get_feature_names())\n",
    "data5.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   abastecimiento  abogado  abril  abril junio  abril mayo  abriljunio  abrir  \\\n",
       "0             0.0      0.0    0.0          0.0         0.0         0.0    0.0   \n",
       "\n",
       "   aca  academico  acceder  ...  walmart  washington  web  wti  yapocl  york  \\\n",
       "0  0.0        0.0      0.0  ...      0.0         0.0  0.0  0.0     0.0   0.0   \n",
       "\n",
       "   zaldivar  zona  zona euro  zonas  \n",
       "0       0.0   0.0        0.0    0.0  \n",
       "\n",
       "[1 rows x 3000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abastecimiento</th>\n      <th>abogado</th>\n      <th>abril</th>\n      <th>abril junio</th>\n      <th>abril mayo</th>\n      <th>abriljunio</th>\n      <th>abrir</th>\n      <th>aca</th>\n      <th>academico</th>\n      <th>acceder</th>\n      <th>...</th>\n      <th>walmart</th>\n      <th>washington</th>\n      <th>web</th>\n      <th>wti</th>\n      <th>yapocl</th>\n      <th>york</th>\n      <th>zaldivar</th>\n      <th>zona</th>\n      <th>zona euro</th>\n      <th>zonas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 3000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Tfidf de palabras por texto\n",
    "vect = TfidfVectorizer(max_features=3000, ngram_range=(1,2))\n",
    "vdat = vect.fit_transform(pdata)\n",
    "data6 = pd.DataFrame(vdat.toarray(), columns=vect.get_feature_names())\n",
    "data6.head(1)"
   ]
  },
  {
   "source": [
    "# Separación de la muestra\n",
    "\n",
    "A continuación se separa la muestra en tres subconjuntos de datos, seleccionados de forma aleatoria y estratificada, de forma tal que la distribución de la variable dependiente sea la misma en cada subset. Los subsets tienen 949, 409 y 103 textos cada uno, es decir, 65%, 28% y 7% de los datos, respectivamente. \n",
    "\n",
    "Esta separación de la muestra se hace para cada una de las seis matrices de datos. Por eso en la celda final se guardan los índices de los distintos subconjuntos de los datos, para más tarde usarlos para seleccionar las observaciones de cada una de las seis bases de datos procesadas anteriormente.\n",
    "\n",
    "Lógica del modelamiento:\n",
    "- El **subset 1** se usa para entrenar los modelos individuales, seis regresiones logísticas, una para cada matriz de datos, donde cada una contiene los textos procesados de una forma diferente. \n",
    "- Luego, cada uno de los modelos generó predicciones para los subsets 2 y 3. \n",
    "- A continuación, se entrenó el **metamodelo** usando el **subset 2**, es decir, usando las predicciones de los primeros seis modelos para el subset 2 como inputs (como regresores o predictores), y usando la variable dependiente del subset 2. \n",
    "- Finalmente, se evaluó el desempeño de los modelos en el subset 3. \n",
    "\n",
    "Esta estrategia permite **reducir el sobreajuste** de los modelos a los datos.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la variable y se toman muestras\n",
    "y = data['response']\n",
    "X = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.35, stratify=y, random_state=123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.2, stratify=y_val, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[949 409 103]\n[65. 28.  7.]\n"
     ]
    }
   ],
   "source": [
    "samples = np.array([y_train.shape[0], y_val.shape[0], y_test.shape[0]])\n",
    "print(samples)\n",
    "print((samples/sum(samples)*100).round())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i_train = y_train.index\n",
    "i_val = y_val.index\n",
    "i_test = y_test.index"
   ]
  },
  {
   "source": [
    "# Funciones y dataframes útiles\n",
    "\n",
    "A continuación se definen algunas funciones útiles para el posterior modelamiento."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "La primera función calcula métricas para la evaluación del desempeño de los modelos.\n",
    "\n",
    "Estas métricas son:\n",
    "- **CV-Score**: accuracy, obtenida por cross-validation (se trata de una estimación de la accuracy fuera de la muestra). **Accuracy** es una medida que muestra la suma de predicciones correctas (POSITIVOS y NEGATIVOS) sobre el total de predicciones.\n",
    "- **Accuracy**: obtenida comparando los valores reales con los predichos por el modelo. \n",
    "- **AUC**: área bajo la curva ROC. Se interpreta como la probabilidad de que un algoritmo clasificador asigne una mayor probabilidad a una observación clasificada como positiva, que fue seleccionada aleatoriamente, que a una observación clasificada como negativa seleccionada aleatoriamente. Los valores que puede tomar esta área varían entre 0.5 y 1, donde 1 representa un clasificador perfecto, y 0.5 es un clasificador sin capacidad discriminatoria. \n",
    "- **F1 Score**: media harmónica de dos métricas: Precision & Recall. Toma su mejor valor en 1 y su peor valor en 0. \n",
    "\n",
    "\n",
    "- **Precision** muestra qué porcentaje de las observaciones clasificadas como positivas por el modelo son efectivamente positivas (un modelo con alta precisión es un modelo con pocos falsos positivos). \n",
    "- **Recall** (sensitivity) muestra qué porcentaje de las observaciones efectivamente positivas, fueron clasificadas como positivas por el modelo (un modelo con alto recall es un modelo con pocos falsos negativos, es decir, un modelo que clasifica correctamente la mayoría de los casos efectivamente positivos)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las métricas de evaluación. \n",
    "def get_metrics(modelo, y, y_pred, y_pred_proba):\n",
    "    return pd.DataFrame({\n",
    "                'CV-Score': searcher.best_score_,\n",
    "                'Accuracy': accuracy_score(y, y_pred),\n",
    "                'AUC': roc_auc_score(y, y_pred_proba),\n",
    "                'F1 Score': f1_score(y, y_pred)},\n",
    "                index=[modelo])"
   ]
  },
  {
   "source": [
    "La siguiente función toma como input una matriz, y entrega tres subconjuntos de datos. \n",
    "- El input es cualquiera de las seis bases de datos cuyos textos fueron procesados de forma diferente.\n",
    "- El output es un subconjunto de datos seleccionados aleatoriamente, para entrenar los modelos individuales y el metamodelo (subsets 1, 2 y 3)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_X_train(X):\n",
    "    X_train = X.loc[i_train]\n",
    "    X_val = X.loc[i_val]\n",
    "    X_test = X.loc[i_test]\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "source": [
    "La siguiente función guarda las predicciones de cada modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(pred_val, pred_test, modelo, y_pred_proba_val, y_pred_proba_test):\n",
    "    pred_val[modelo] = y_pred_proba_val\n",
    "    pred_test[modelo] = y_pred_proba_test"
   ]
  },
  {
   "source": [
    "También se crean algunos **dataframes vacíos** para almacenar los resultados (métricas de evaluación) y parámetros óptimos de los modelos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames vacíos para almacenar los resultados \n",
    "results = pd.DataFrame()\n",
    "parametros = pd.DataFrame()"
   ]
  },
  {
   "source": [
    "Por último, se crea un diccionario, para almacenar las seis bases de datos, donde en cada una se procesaron los valores, los pesos de las palabras, de forma diferente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con los datos y sus nombres\n",
    "keys = ['data1', 'data2', 'data3', 'data4', 'data5', 'data6']\n",
    "values = [data1, data2, data3, data4, data5, data6]\n",
    "datos = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos primera ronda\n",
    "\n",
    "A continuación se seleccionan los modelos de la primera ronda, es decir, los modelos individuales: las seis regresiones logísticas entrenadas, cada una, con una base de datos distinta. Se optó por la regresión logística (**logit**), ya que se trata de un método más eficiente para el tipo de datos con que se cuenta, donde muchos valores son iguales a cero, y otros toman valores discretos.\n",
    "\n",
    "Para **calibrar** los modelos se usó **5-fold cross-validation** y una **búsqueda de grilla**.\n",
    "\n",
    "La búsqueda de grilla implica ajustar cada modelo utilizando un conjunto de valores para los parámetros exógenos, que en el caso de la **regresión logística** pueden ser: \n",
    "\n",
    "1. tipo de regularización, Lasso o Ridge.\n",
    "2. el parámetro asociado a la regularización (lambda).  \n",
    "\n",
    "Se probaron 20 posibilidades para el valor lambda, que junto con los dos posibles métodos de regularización significó probar 40 combinaciones para cada uno de los seis modelos individuales. De esta manera se seleccionó la combinación óptima de parámetros, que es aquella que minimiza el CV-Error (CV-Score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "data1 Best CV params {'C': 1.623776739188721, 'penalty': 'l2'}\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "data2 Best CV params {'C': 0.615848211066026, 'penalty': 'l2'}\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "data3 Best CV params {'C': 10000.0, 'penalty': 'l2'}\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "data4 Best CV params {'C': 3792.690190732246, 'penalty': 'l2'}\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "data5 Best CV params {'C': 10000.0, 'penalty': 'l2'}\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "data6 Best CV params {'C': 1438.44988828766, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=123)\n",
    "parameters = {'C':np.logspace(-4, 4, 20), \n",
    "               'penalty':['l1', 'l2']}\n",
    "searcher = GridSearchCV(estimator=model, \n",
    "                        param_grid=parameters, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=-1, \n",
    "                        verbose=1)\n",
    "\n",
    "for key, value in datos.items():\n",
    "    X_train, X_val, X_test = gen_X_train(value)\n",
    "    \n",
    "    searcher.fit(X_train, y_train)\n",
    "    \n",
    "    print(key, \"Best CV params\", searcher.best_params_)\n",
    "    parametros = parametros.append(pd.DataFrame(searcher.best_params_, index=[key]))\n",
    "\n",
    "    best_model = searcher.best_estimator_\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred_proba_train = best_model.predict_proba(X_train)[:,1]\n",
    "    results = results.append(get_metrics(key, y_train, y_pred_train, y_pred_proba_train))"
   ]
  },
  {
   "source": [
    "# Resultados primera ronda\n",
    "\n",
    "A continuación se muestran los resultados para la primera ronda.\n",
    "- El mejor modelo según CV-Score fue el 5 (tf-idf para palabras individuales).\n",
    "- Según todas las demás mérticas el mejor modelo fue el 1 (recuento de palabras individuales)\n",
    "\n",
    "El CV-Score muestra que el f1 score se encontró cerca de 0.70 fuera de la muestra (*out-of-sample*). Las otras métricas muestran que, dentro de la muestra (*in-sample*), la clasificación fue prácticamente perfecta. La diferencia entre ambas métricas indica sobreajuste."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best models:\nCV-Score    data5\nAccuracy    data1\nAUC         data1\nF1 Score    data1\ndtype: object \n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       CV-Score  Accuracy  AUC  F1 Score\n",
       "data1  0.702219  1.000000  1.0  1.000000\n",
       "data2  0.704159  1.000000  1.0  1.000000\n",
       "data3  0.683685  1.000000  1.0  1.000000\n",
       "data4  0.680060  0.998946  1.0  0.997712\n",
       "data5  0.704350  1.000000  1.0  1.000000\n",
       "data6  0.700581  1.000000  1.0  1.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CV-Score</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>data1</th>\n      <td>0.702219</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>data2</th>\n      <td>0.704159</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>data3</th>\n      <td>0.683685</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>data4</th>\n      <td>0.680060</td>\n      <td>0.998946</td>\n      <td>1.0</td>\n      <td>0.997712</td>\n    </tr>\n    <tr>\n      <th>data5</th>\n      <td>0.704350</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>data6</th>\n      <td>0.700581</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "print('Best models:')\n",
    "print(results.idxmax(), '\\n')\n",
    "results"
   ]
  },
  {
   "source": [
    "Por último, se guardan los mejores parámetros identificados para su posterior utilización."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  C penalty\n",
       "data1      1.623777      l2\n",
       "data2      0.615848      l2\n",
       "data3  10000.000000      l2\n",
       "data4   3792.690191      l2\n",
       "data5  10000.000000      l2\n",
       "data6   1438.449888      l2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>penalty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>data1</th>\n      <td>1.623777</td>\n      <td>l2</td>\n    </tr>\n    <tr>\n      <th>data2</th>\n      <td>0.615848</td>\n      <td>l2</td>\n    </tr>\n    <tr>\n      <th>data3</th>\n      <td>10000.000000</td>\n      <td>l2</td>\n    </tr>\n    <tr>\n      <th>data4</th>\n      <td>3792.690191</td>\n      <td>l2</td>\n    </tr>\n    <tr>\n      <th>data5</th>\n      <td>10000.000000</td>\n      <td>l2</td>\n    </tr>\n    <tr>\n      <th>data6</th>\n      <td>1438.449888</td>\n      <td>l2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "parametros.to_csv('parametros_1.csv')\n",
    "parametros"
   ]
  },
  {
   "source": [
    "# Ajuste de los modelos a la muestra completa\n",
    "\n",
    "A continuación se ajustan los modelos a la muestra completa. Hay que mencionar que este paso es redundante, ya que sklearn hace esto automáticamente después de elegir el mejor modelo a través de la búsqueda de grilla. Eso no lo sabía al momento de hacer esto, pero se aprovecha la instancia para guaardar las predicciones de los modelos, que se usarán como inputs del metamodelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames vacíos para almacenar los resultados \n",
    "pred_val = pd.DataFrame()\n",
    "pred_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in datos.items():\n",
    "    X_train, X_val, X_test = gen_X_train(value)\n",
    "\n",
    "    model = LogisticRegression(random_state=123,\n",
    "                                C=parametros.loc[key][0],\n",
    "                                penalty=parametros.loc[key][1])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba_val = model.predict_proba(X_val)[:,1]\n",
    "    y_pred_proba_test = model.predict_proba(X_test)[:,1]\n",
    "    save_preds(pred_val, pred_test, key, y_pred_proba_val, y_pred_proba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val.index = i_val\n",
    "pred_test.index = i_test"
   ]
  },
  {
   "source": [
    "# Segunda ronda: Stacking\n",
    "\n",
    "A continuación se elige el **metamodelo**. Este es un método de ensemble (ensamblado o meta ensamblado), donde se combinan las predicciones de otros modelos, para obtener una predicción superior a la de los modelos individuales.\n",
    "\n",
    "Se repitió la búsqueda de grilla con cross-validation para el metamodelo, de forma de seleccionar sus parámetros óptimos. El metamodelo también es una regresión logística, y se buscó en la misma grilla utilizada en los modelos individuales. Una vez elegido el mejor metamodelo, se ajustó al subset2 completo y se hizo la predicción para el subset 3. Por último, se guardaron los parámetros óptimos.\n",
    "\n",
    "Notar que los resultados no son tan buenos como los anteriores, lo que se debe a que el metamodelo se entrenó con datos distintos, usando las predicciones (fuera de la muestra) de los modelos anteriores como inputs, no se usaron los textos originales. Esto se hace así para reducir el sobreajuste del metamodelo. Además, todas las métricas de error son 'out-of-sample', ya que se estimaron, ya sea por cross-validation, o bien usando el subset 3 (no utilizado hasta ahora). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pred_val\n",
    "X_test = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames vacíos para almacenar los resultados \n",
    "parametros = pd.DataFrame()\n",
    "results = pd.DataFrame()\n",
    "pred_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best CV params {'C': 29.763514416313132, 'penalty': 'l2'}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    CV-Score  Accuracy     AUC  F1 Score\n",
       "LR    0.6731    0.8641  0.9014    0.6667"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CV-Score</th>\n      <th>Accuracy</th>\n      <th>AUC</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LR</th>\n      <td>0.6731</td>\n      <td>0.8641</td>\n      <td>0.9014</td>\n      <td>0.6667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "modelo = 'LR'\n",
    "model = LogisticRegression(random_state=123)\n",
    "parameters = {'C':np.logspace(-4, 4, 20), \n",
    "              'penalty':['l1', 'l2']}\n",
    "searcher = GridSearchCV(estimator=model, \n",
    "                        param_grid=parameters, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=-1, \n",
    "                        verbose=1)\n",
    "searcher.fit(X_val, y_val)\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "parametros = parametros.append(pd.DataFrame(searcher.best_params_, index=[key]))\n",
    "\n",
    "best_model = searcher.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "pred_test[modelo] = y_pred_proba\n",
    "\n",
    "results = results.append(get_metrics(modelo, y_test, y_pred, y_pred_proba))\n",
    "results.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               C penalty\n",
       "data6  29.763514      l2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>penalty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>data6</th>\n      <td>29.763514</td>\n      <td>l2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "parametros.to_csv('parametros_2.csv')\n",
    "parametros"
   ]
  },
  {
   "source": [
    "# Ajuste del mejor modelo a la muestra completa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'LR'\n",
    "model = LogisticRegression(random_state=123,\n",
    "                            C=parametros['C'].iloc[0],\n",
    "                            penalty=parametros['penalty'].iloc[0])\n",
    "model.fit(X_val, y_val)\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "source": [
    "# Optimizar threshold\n",
    "\n",
    "El último paso es **optimizar el threshold**. \n",
    "\n",
    "El metamodelo entrega como predicción la probabilidad de que un texto sea optimista, que es un valor entre 0.0 y 1.0. \n",
    "\n",
    "Para hacer una predicción de las etiquetas 0 y 1 se necesita un threshold (un umbral) tal que una probabilidad mayor al threshold se considere como un 1 (etiqueta positiva). \n",
    "\n",
    "- Para optimizar el threshold se hizo una búsqueda de grilla sencilla, en 300 valores equidistantes entre 0 y 1. \n",
    "- Se optimizó usando como referencia la métrica **F1 Score**, que es la media harmónica de otras dos métricas precision (porcentaje de los datos clasificados como positivos por el modelo que son efectivamente positivos) y recall (porcentaje de los datos efectivamente positivos que fueron clasificados como positivos por el modelo). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para transformar probabilidad en label\n",
    "def to_labels(y_pred_proba, threshold):\n",
    "\treturn (y_pred_proba >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferentes thresholds a testear\n",
    "thresholds = np.linspace(0, 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR Threshold=0.1873, F-Score=0.7234\n"
     ]
    }
   ],
   "source": [
    "# Optimización del threshold en base a F1 Score\n",
    "scores = [f1_score(y_test, to_labels(y_pred_proba, t)) for t in thresholds]\n",
    "ix = np.argmax(scores)\n",
    "print(modelo, 'Threshold=%.4f, F-Score=%.4f' % (thresholds[ix], scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_proba >= thresholds[ix]).astype(int)\n",
    "y_pred = pd.DataFrame(y_pred, columns=['y_pred'], index=y_test.index)"
   ]
  },
  {
   "source": [
    "Finalmente se calcula la accuracy del metamodelo tras optimizar el threshold. Se encuentra que clasifica correctamente el 87% de los sentimientos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy=0.8738\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy=%.4f' % accuracy_score(y_test, y_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      response  y_pred  Accuracy\n",
       "531        0.0       0      True\n",
       "761        0.0       0      True\n",
       "848        0.0       0      True\n",
       "362        0.0       0      True\n",
       "696        0.0       0      True\n",
       "...        ...     ...       ...\n",
       "74         0.0       0      True\n",
       "1053       0.0       0      True\n",
       "1201       1.0       1      True\n",
       "1236       0.0       0      True\n",
       "201        0.0       0      True\n",
       "\n",
       "[103 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>response</th>\n      <th>y_pred</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>531</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>848</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>1.0</td>\n      <td>1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1236</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>103 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "pred = pd.concat([y_test, y_pred], axis=1)\n",
    "pred['Accuracy'] = (pred['response']==pred['y_pred'])\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}